Набор данных содержит информацию о 20 000 записях в 58 столбцах, охватывающих различные аспекты данных о клиентах, такие
как ежемесячный доход, сведения о звонках, информация об услугах и демографические атрибуты. Вот краткое изложение
ключевых моментов о наборе данных:

1. **Отсутствующие значения**:
    - В столбце «Отток» отсутствуют все значения (0 ненулевых записей), что может использоваться в качестве контрольного
      набора для прогнозирования.
    - В некоторых столбцах, таких как MonthlyRevenue, MonthlyMinutes, TotalRecurringCharge и других, отсутствуют
      некоторые значения. Например, MonthlyRevenue отсутствует для 60 записей.

2. **Типы данных**:
    - Большинство столбцов являются числовыми (float64 или int64), подходящими для анализа.
    - ServiceArea (пример) — это категориальный столбец (тип «объект»).

3. **Статистическая сводка**:
    - Непрерывные переменные, такие как MonthlyRevenue и MonthlyMinutes, демонстрируют широкий диапазон, что указывает
      на разнообразное поведение клиентов.
    - Некоторые категориальные данные, такие как UniqueSubs и ActiveSubs, показывают различия в деталях подписки для
      каждого клиента.

Исходя из результатов тестирования трех различных алгоритмов кластеризации — пользовательского KMeans, KMeans из scikit-learn и DBSCAN из scikit-learn, можно сделать следующие выводы:

### Время выполнения:

1. **Время пользовательского KMeans**: 0.124 секунды. Это метод занимает среднее время по сравнению с другими протестированными методами.
2. **Время KMeans**: 0.015 секунды. KMeans из scikit-learn работает значительно быстрее всех других реализаций, что может быть результатом внутренней оптимизации алгоритма.
3. **Время DBSCAN**: 0.529 секунды. Этот метод занимает больше времени, чем KMeans, что обусловлено более сложными вычислениями для определения плотности кластеров.

### Метрики качества кластеризации:

Качество кластеризации оценивалось по трем показателям: Silhouette Score, Davies-Bouldin Score и Calinski-Harabasz Index.

- **Оценка силуэта** (Silhouette Score) является мерой того, насколько хорошо объекты сгруппированы в кластерах по сравнению с другими кластерами. Высокое значение указывает на хорошее разделение кластеров.
- **Оценка Дэвиса-Булдина** (Davies-Bouldin Score) показывает среднее «сходство» между кластерами. Низкое значение указывает на лучшее разделение между кластерами.
- **Индекс Калински-Харабаша** (Calinski-Harabasz Index) измеряет соотношение дисперсий между кластерами и внутри кластеров. Высокие значения говорят о хорошо разделенных и плотно сгруппированных кластерах.

#### Пользовательский KMeans:

- **Оценка силуэта**: 0.3822, что указывает на умеренно хорошую обособленность и сплоченность кластеров.
- **Оценка Дэвиса-Булдина**: 1.820, показывает достаточно хорошее разделение кластеров.
- **Индекс Калински-Харабаша**: 3790.373, демонстрирует отличное качество кластеризации с хорошей плотностью и разделением.

#### KMeans (scikit-learn):

- **Оценка силуэта**: 0.3829, практически идентична пользовательскому KMeans, что свидетельствует о сопоставимом качестве кластеризации.
- **Оценка Дэвиса-Булдина**: 1.819, немного лучше, чем у пользовательского KMeans.
- **Индекс Калински-Харабаша**: 3790.375, очень близко к пользовательскому KMeans, подтверждает высокую эффективность алгоритма.

#### DBSCAN:

- **Оценка силуэта**: 0.0191, значительно ниже, чем у KMeans, указывает на плохую раздельность кластеров.
- **Оценка Дэвиса-Булдина**: 1.456, лучше, чем у KMeans, что может указывать на лучшее разделение кластеров в отдельных случаях.
- **Индекс Калински-Харабаша**: 269.812, значительно ниже, чем у KMeans, что свидетельствует о низкой плотности и разделении кластеров.

### Заключение:

- **KMeans (scikit-learn)** продемонстрировал лучший баланс времени выполнения и качества кластеризации, делая его предпочтительным выбором для анализа.
- **Пользовательский KMeans** показал сопоставимые результаты по качеству, но с немного большим временем выполнения.
- **DBSCAN**, хотя и обеспечил лучший показатель Дэвиса-Булдина, показал значительно худшие результаты по другим метрикам, что делает его менее подходящим для данного набора данных из-за его чувствительности к параметрам и шуму.