# Эксперимент A: Обучение UNet

## Описание эксперимента
В этом эксперименте мы обучали модель UNet. Целью было понять, как модель будет работать на ограниченном наборе данных и сможет ли она достичь приемлемого качества сегментации.

## Архитектура модели
Мы использовали базовую архитектуру UNet со следующими характеристиками:
- Входные каналы: 3 (RGB изображения)
- Начальные выходные каналы: 64
- Конечные выходные каналы: 1 (бинарная маска)
- Четыре шага понижения и повышения разрешения

## Процесс обучения
- Функция потерь: Dice Loss
- Оптимизатор: Adam с learning rate 1e-4
- Размер пакета: 4
- Количество эпох: 20
- Аугментация данных: отсутствует

## Результаты
Производительность модели оценивалась с помощью метрики IoU (Intersection over Union) на тестовом наборе данных. Ниже приведены результаты по эпохам:

| Эпоха | Потери на обучении | IoU на тесте |
|-------|--------------------|--------------|
| 1     | 3.3669             | 0.1572       |
| 2     | 5.6425             | 0.1572       |
| 3     | 1.2259             | 0.1572       |
| 4     | 3.6452             | 0.1572       |
| 5     | 2.6132             | 0.1136       |
| 6     | 3.7147             | 0.0712       |
| 7     | 1.8407             | 0.1085       |
| 8     | 1.6920             | 0.1532       |
| 9     | 1.5801             | 0.1991       |
| 10    | 1.5605             | 0.2140       |
| 11    | 1.5155             | 0.2021       |
| 12    | 1.6225             | 0.1871       |
| 13    | 1.5742             | 0.2007       |
| 14    | 1.4481             | 0.2029       |
| 15    | 1.5323             | 0.2134       |
| 16    | 1.6312             | 0.2175       |
| 17    | 1.4252             | 0.2184       |
| 18    | 1.4053             | 0.2168       |
| 19    | 1.4272             | 0.2098       |
| 20    | 1.3772             | 0.2286       |

Итоговый показатель IoU на тестовом наборе данных составил 0.2286.

## Вывод
Результаты показывают, что модель UNet, обученная без использования аугментаций данных, смогла достичь конечного показателя IoU 0.2286. Это демонстрирует начальный потенциал модели, но указывает на необходимость улучшений для достижения более высоких показателей.

# Эксперимент B: Обучение UNet с аугментацией данных

## Описание эксперимента
В этом эксперименте мы добавили методы аугментации данных, чтобы улучшить производительность модели UNet. Использовалась та же архитектура модели.

## Архитектура модели
- Входные каналы: 3 (RGB изображения)
- Начальные выходные каналы: 64
- Конечные выходные каналы: 1 (бинарная маска)
- Четыре шага понижения и повышения разрешения

## Процесс обучения
- Функция потерь: Dice Loss
- Оптимизатор: Adam с learning rate 1e-4
- Размер пакета: 8
- Количество эпох: 20

### Аугментация данных
- Изменение размера до 256x256
- Случайное кадрирование до 224x224
- Горизонтальное отражение с вероятностью 0.5
- Вращение с ограничением 15 градусов
- Изменение яркости, контрастности и насыщенности

## Результаты
Производительность модели оценивалась с помощью метрики IoU на тестовом наборе данных. Ниже приведены результаты по эпохам:

| Эпоха | Потери на обучении | IoU на тесте |
|-------|--------------------|--------------|
| 1     | 1.5295             | 0.0332       |
| 2     | 1.3994             | 0.0332       |
| 3     | 1.1030             | 0.0332       |
| 4     | 0.9365             | 0.0337       |
| 5     | 0.7758             | 0.0358       |
| 6     | 0.8209             | 0.1072       |
| 7     | 0.9178             | 0.0801       |
| 8     | 1.0722             | 0.0660       |
| 9     | 1.0059             | 0.0645       |
| 10    | 0.8906             | 0.0651       |
| 11    | 1.0910             | 0.0691       |
| 12    | 1.0192             | 0.0734       |
| 13    | 1.2417             | 0.0750       |
| 14    | 0.9713             | 0.0815       |
| 15    | 1.0192             | 0.0901       |
| 16    | 0.9194             | 0.1088       |
| 17    | 0.9442             | 0.1386       |
| 18    | 0.7280             | 0.1767       |
| 19    | 0.8506             | 0.2017       |
| 20    | 0.7570             | 0.2230       |

### Аугментация во время тестирования (TTA)
Итоговый показатель IoU с TTA составил 0.2220.

## Вывод
Добавление аугментаций данных значительно улучшило производительность модели на начальных этапах обучения, однако итоговый показатель IoU 0.2220 показал, что улучшение качества сегментации не было устойчивым на протяжении всех эпох. Тем не менее, аугментации данных показали свою важность в улучшении обучаемости модели.

# Эксперимент C: Обучение UNet с предварительно обученным энкодером ResNet18

## Описание эксперимента
В этом эксперименте мы исследовали использование предварительно обученного энкодера ResNet18 в архитектуре UNet, чтобы улучшить производительность модели.

## Архитектура модели
- Энкодер: предварительно обученный ResNet18
- Декодер: модифицирован для соответствия размерам выходных данных энкодера
- Входные каналы: 3 (RGB изображения)
- Конечные выходные каналы: 1 (бинарная маска)

## Процесс обучения
- Функция потерь: Dice Loss
- Оптимизатор: Adam с learning rate 1e-4
- Размер пакета: 8
- Количество эпох: 20

## Результаты
Производительность модели оценивалась с помощью метрики IoU на тестовом наборе данных. Ниже приведены результаты по эпохам:

| Эпоха | Потери на обучении | IoU на тесте |
|-------|--------------------|--------------|
| 1     | 0.6580             | 0.2582       |
| 2     | 0.4444             | 0.1791       |
| 3     | 0.2418             | 0.1365       |
| 4     | 0.0832             | 0.1371       |
| 5     | -0.2239            | 0.1508       |
| 6     | -0.0580            | 0.1393       |
| 7     | -1.1960            | 0.1067       |
| 8     | -6.0381            | 0.0837       |
| 9     | -0.5317            | 0.1080       |
| 10    | -2.2579            | 0.1115       |
| 11    | -0.6747            | 0.1285       |
| 12    | 0.2183             | 0.1444       |
| 13    | -0.0871            | 0.1539       |
| 14    | 0.3994             | 0.1598       |
| 15    | 1.8974             | 0.1561       |
| 16    | 0.2812             | 0.1530       |
| 17    | 0.1525             | 0.1650       |
| 18    | 0.1864             | 0.1785       |
| 19    | -2.7886            | 0.1813       |
| 20    | -4.0243            | 0.1391       |

### Аугментация во время тестирования (TTA)
Итоговый показатель IoU с TTA составил 0.2656.

## Вывод
Использование предварительно обученного энкодера ResNet18 позволило достичь более высоких показателей IoU, особенно при применении аугментаций во время тестирования. Итоговый IoU с TTA составил 0.2656, что является лучшим результатом среди всех экспериментов.

# Эксперимент D: Кросс-валидация с UNet и предварительно обученным энкодером ResNet18

## Описание эксперимента
В этом эксперименте мы использовали 5-кратную кросс-валидацию для оценки модели UNet с предварительно обученным энкодером ResNet18.

## Архитектура модели
- Энкодер: предварительно обученный ResNet18
- Декодер: модифицирован для соответствия размерам выходных данных энкодера
- Входные каналы: 3 (RGB изображения)
- Конечные выходные каналы: 1 (бинарная маска)

## Процесс обучения
- Функция потерь: Dice Loss
- Оптимизатор: Adam с learning rate 1e-4
- Размер пакета: 8
- Количество эпох: 20

## Результаты
Производительность модели оценивалась с помощью метрики IoU на валидационном наборе данных. Ниже приведены результаты по эпохам для каждого фолда:

### Фолд 1

| Эпоха | Потери на обучении | IoU на валидации |
|-------|--------------------|------------------|
| 1     | 0.7013             | 0.5356           |
| 2     | 0.4974             | 0.5280           |
| 3     | 0.4991             | 0.4175           |
| 4     | 0.3558             | 0.3659           |
| 5     | 0.2902             | 0.3820           |
| 6     | 0.1444             | 0.4169           |
| 7     | 0.1809             | 0.4322           |
| 8     | -0.0364            | 0.4183           |
| 9     | 0.0028             | 0.4233           |
| 10    | 1.6732             | 0.4178           |
| 11    | 3.6972             | 0.3727           |
| 12    | 2.2967             | 0.3422           |
| 13    | -0.0679            | 0.3229           |
| 14    | 0.0334             | 0.3303           |
| 15    | 0.4338             | 0.3401           |
| 16    | 0.4203             | 0.3463           |
| 17    | 0.2642             | 0.3484           |
| 18    | 0.4974             | 0.3472           |
| 19    | 0.3182             | 0.3400           |
| 20    | 0.6375             | 0.3520           |

### Фолд 2

| Эпоха | Потери на обучении | IoU на валидации |
|-------|--------------------|------------------|
| 1     | 1.0246             | 0.0065           |
| 2     | 0.8122             | 0.0065           |
| 3     | 0.7668             | 0.0065           |
| 4     | 0.6352             | 0.0065           |
| 5     | 0.6454             | 0.0065           |
| 6     | 0.5866             | 0.0076           |
| 7     | 0.4517             | 0.0136           |
| 8     | 0.3536             | 0.0148           |
| 9     | 0.3411             | 0.0104           |
| 10    | 0.2615             | 0.0143           |
| 11    | -0.1734            | 0.0182           |
| 12    | 1.6566             | 0.2560           |
| 13    | 0.8038             | 0.4354           |
| 14    | -0.4348            | 0.4090           |
| 15    | 0.9421             | 0.3392           |
| 16    | 0.2486             | 0.1475           |
| 17    | -5.2129            | 0.3820           |
| 18    | 0.8157             | 0.4193           |
| 19    | 0.5247             | 0.4364           |
| 20    | 0.4201             | 0.4538           |

### Фолд 3

| Эпоха | Потери на обучении | IoU на валидации |
|-------|--------------------|------------------|
| 1     | 0.9971             | 0.0456           |
| 2     | 0.8341             | 0.0456           |
| 3     | 0.9246             | 0.0456           |
| 4     | 0.6412             | 0.0456           |
| 5     | 0.4841             | 0.0456           |
| 6     | 0.4023             | 0.0456           |
| 7     | 0.3291             | 0.0456           |
| 8     | 0.1504             | 0.0431           |
| 9     | 0.2315             | 0.0333           |
| 10    | 0.4390             | 0.0949           |
| 11    | -0.1164            | 0.2185           |
| 12    | 0.4656             | 0.2793           |
| 13    | 0.2402             | 0.2851           |
| 14    | 3.3566             | 0.3172           |
| 15    | 0.8097             | 0.3671           |
| 16    | 0.4137             | 0.4471           |
| 17    | 0.6833             | 0.4521           |
| 18    | -4.5720            | 0.4348           |
| 19    | -0.0503            | 0.3745           |
| 20    | 4.6543             | 0.3281           |

### Фолд 4

| Эпоха | Потери на обучении | IoU на валидации |
|-------|--------------------|-----------------|
| 1     | 1.3459             | 0.4756          |
| 2     | 0.9282             | 0.4758          |
| 3     | 0.7528             | 0.4715          |
| 4     | 0.9962             | 0.4506          |
| 5     | 0.6847             | 0.4388          |
| 6     | 0.4708             | 0.4604          |
| 7     | 0.4753             | 0.4679          |
| 8     | 0.2272             | 0.4698          |
| 9     | 4.7766             | 0.4723          |
| 10    | 1.0181             | 0.4733          |
| 11    | 0.7279             | 0.4730          |
| 12    | 0.4490             | 0.4730          |
| 13    | 1.0211             | 0.4724          |
| 14    | 0.9310             | 0.4702          |
| 15    | 1.4398             | 0.4672          |
| 16    | 2.4581             | 0.4638          |
| 17    | -1.6213            | 0.4610          |
| 18    | 0.8340             | 0.4575          |
| 19    | 0.6569             | 0.4533          |
| 20    | 0.7020             | 0.4475          |

### Фолд 5

| Эпоха | Потери на обучении | IoU на валидации |
|-------|--------------------|------------------|
| 1     | 0.6781             | 0.4919           |
| 2     | 0.4323             | 0.4919           |
| 3     | 0.2742             | 0.4919           |
| 4     | 0.1845             | 0.4920           |
| 5     | 0.1444             | 0.4924           |
| 6     | 0.0018             | 0.4886           |
| 7     | -0.3193            | 0.4231           |
| 8     | 0.0919             | 0.3910           |
| 9     | 0.6014             | 0.3799           |
| 10    | 0.5630             | 0.3960           |
| 11    | 0.6872             | 0.4672           |
| 12    | -1.3937            | 0.4977           |
| 13    | 0.4045             | 0.4890           |
| 14    | 0.1904             | 0.4372           |
| 15    | 0.3092             | 0.4227           |
| 16    | 0.1863             | 0.4168           |
| 17    | 1.2798             | 0.4139           |
| 18    | 0.4525             | 0.4116           |
| 19    | 1.4457             | 0.4152           |
| 20    | 0.6638             | 0.4232           |

## Вывод
Результаты кросс-валидации показали, что производительность модели может значительно варьироваться в зависимости от набора данных для обучения и валидации. Наилучший показатель IoU на валидации достиг 0.5356 в первом фолде. Это указывает на важность использования кросс-валидации для получения более стабильных и надежных оценок производительности модели.